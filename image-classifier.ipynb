{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2uffHZLCPMU",
        "outputId": "a2bf1a9b-946a-4b8c-f5f1-f068fe45cc1f"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyxmEoX11W5u"
      },
      "source": [
        "#Step 1: Download a dataset and preview images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZqRJrYBAff",
        "outputId": "631895c6-65c7-4cdf-8970-4e23237aaf8f"
      },
      "outputs": [],
      "source": [
        "!tar -xvf './cifar100.tar'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woI6j0f5BTGl"
      },
      "source": [
        "# Step 2: Custom Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnU8jRXoBaX_",
        "outputId": "506e2783-df01-4f8e-d6ec-f3e4af0faf1e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "import torch\n",
        "import shutil\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "config = {\n",
        "    \"data_path\":\"./cifar100\",\n",
        "    \"batch_size\":2,\n",
        "}\n",
        "\n",
        "class mydataset(Dataset):\n",
        "    def __init__(self, data_dir, flag, transform):\n",
        "        super(mydataset,self).__init__()\n",
        "        self.root       = data_dir\n",
        "        self.label      = flag\n",
        "        self.transform  = transform\n",
        "\n",
        "        self.img_dir = os.path.join(self.root, self.label)\n",
        "        self.img_names  = glob.glob(os.path.join(self.img_dir, '*.jpg'))\n",
        "\n",
        "        self.tags = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
        "\n",
        "    def RGB2Gradient(self, img:torch.tensor):\n",
        "        \"\"\"\n",
        "        Converts an RGB image tensor to its gradient magnitude using Sobel operator.\n",
        "        The output is replicated to 3 channels to match the input dimensions of the other branch.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Define Sobel kernels\n",
        "        sobel_kernel_x = torch.tensor([[-1., 0., 1.], \n",
        "                                       [-2., 0., 2.], \n",
        "                                       [-1., 0., 1.]], dtype=torch.float32).reshape((1, 1, 3, 3))\n",
        "        sobel_kernel_y = torch.tensor([[-1., -2., -1.], \n",
        "                                       [ 0.,  0.,  0.], \n",
        "                                       [ 1.,  2.,  1.]], dtype=torch.float32).reshape((1, 1, 3, 3))\n",
        "\n",
        "        sobel_kernel_x = sobel_kernel_x.to(img.device)\n",
        "        sobel_kernel_y = sobel_kernel_y.to(img.device)\n",
        "\n",
        "        # Convert to grayscale: [3, H, W] -> Output [1, H, W]\n",
        "        # gray_img = img[0, :, :] * 0.2989 + img[1, :, :] * 0.5870 + img[2, :, :] * 0.1140\n",
        "        # gray_img = gray_img.unsqueeze(0)\n",
        "        gray_img = transforms.Grayscale(num_output_channels=1)(img)\n",
        "\n",
        "        # Add batch dimension [1, H, W] -> [1, 1, H, W]\n",
        "        gray_img_batch = gray_img.unsqueeze(0) \n",
        "\n",
        "        # [YOU NEED TO FILL] Apply Sobel filters\n",
        "        # Use F.conv2d, gray_img_batch, and the Sobel kernels (sobel_kernel_x, sobel_kernel_y) \n",
        "        # to calculate the gradients in the x and y directions.\n",
        "        grad_x = ...\n",
        "        grad_y = ...\n",
        "        \n",
        "        # [YOU NEED TO FILL] Calculate gradient magnitude ---\n",
        "        # Calculate the magnitude (G = sqrt(Gx^2 + Gy^2)) from grad_x and grad_y.\n",
        "        # The result should be stored in a variable named 'magnitude'.\n",
        "        magnitude = ...\n",
        "\n",
        "        # Normalize magnitude\n",
        "        mag_min = magnitude.min()\n",
        "        mag_max = magnitude.max()\n",
        "        epsilon = 1e-6 # Avoid division by zero\n",
        "        normalized_magnitude = (magnitude - mag_min) / (mag_max - mag_min + epsilon)\n",
        "        \n",
        "        # Replicate to 3 channels [1, 1, H, W] -> [1, 3, H, W]\n",
        "        normalized_magnitude_3channel = normalized_magnitude.repeat(1, 3, 1, 1)\n",
        "\n",
        "        # Remove batch dimension [1, 3, H, W] -> [3, H, W]\n",
        "        return normalized_magnitude_3channel.squeeze(0)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img_name = self.img_names[idx]\n",
        "        img = Image.open(os.path.join(img_name))\n",
        "        img = self.transform(img)\n",
        "\n",
        "        for i in range(len(self.tags)):\n",
        "            if self.tags[i] in img_name:\n",
        "                tag = i\n",
        "                break\n",
        "\n",
        "        return img, tag\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "transform_train = transforms.Compose(\n",
        "        [transforms.Resize([64, 64]),\n",
        "         transforms.ToTensor()])\n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.Resize([64, 64]),\n",
        "      transforms.ToTensor()])\n",
        "\n",
        "train_dataset = mydataset(data_dir=config['data_path'], flag= \"train\", transform=transform_train)\n",
        "test_dataset  = mydataset(data_dir=config['data_path'], flag= \"test\", transform=transform_test)\n",
        "\n",
        "# define data loader\n",
        "train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True, drop_last=False)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config['batch_size'], shuffle=True, num_workers=4, pin_memory=True, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0io-L6VCDoB"
      },
      "source": [
        "# Step 3: Configure the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jvia9QHCHtC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import Sequential as Seq\n",
        "\n",
        "class CommonBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, stride):        # 普通Block简单完成两次卷积操作\n",
        "        super(CommonBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x                                            # 普通Block的shortcut为直连，不需要升维下采样\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)       # 完成一次卷积\n",
        "        x = self.bn2(self.conv2(x))                             # 第二次卷积不加relu激活函数\n",
        "\n",
        "        x += identity                                           # 两路相加\n",
        "        return F.relu(x, inplace=True)                          # 添加激活函数输出\n",
        "\n",
        "class SpecialBlock(nn.Module):                                  # 特殊Block完成两次卷积操作，以及一次升维下采样\n",
        "    def __init__(self, in_channel, out_channel, stride):        # 注意这里的stride传入一个数组，shortcut和残差部分stride不同\n",
        "        super(SpecialBlock, self).__init__()\n",
        "        self.change_channel = nn.Sequential(                    # 负责升维下采样的卷积网络change_channel\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride[0], padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channel)\n",
        "        )\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride[0], padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride[1], padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.change_channel(x)                       # 调用change_channel对输入修改，为后面相加做变换准备\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
        "        x = self.bn2(self.conv2(x))                             # 完成残差部分的卷积\n",
        "\n",
        "        x += identity\n",
        "        return F.relu(x, inplace=True)                          # 输出卷积单元\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, classes_num):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.prepare = nn.Sequential(           # 预处理==》[batch, 64, 56, 56]\n",
        "            nn.Conv2d(3, 64, 7, 2, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, 2, 1)\n",
        "        )\n",
        "        self.layer1 = nn.Sequential(            # layer1有点特别，由于输入输出的channel均是64，故两个CommonBlock\n",
        "            CommonBlock(64, 64, 1),\n",
        "            CommonBlock(64, 64, 1)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(            # layer234类似，由于输入输出的channel不同，故一个SpecialBlock，一个CommonBlock\n",
        "            SpecialBlock(64, 128, [2, 1]),\n",
        "            CommonBlock(128, 128, 1)\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            SpecialBlock(128, 256, [2, 1]),\n",
        "            CommonBlock(256, 256, 1)\n",
        "        )\n",
        "        self.layer4 = nn.Sequential(\n",
        "            SpecialBlock(256, 512, [2, 1]),\n",
        "            CommonBlock(512, 512, 1)\n",
        "        )\n",
        "        self.head = Seq(nn.AdaptiveAvgPool2d(1),\n",
        "                  nn.Flatten(start_dim=1),\n",
        "                  nn.Linear(512, classes_num))\n",
        "    def forward(self, x):\n",
        "        x = self.prepare(x)         # 预处理\n",
        "\n",
        "        x = self.layer1(x)          # 四个卷积单元\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.head(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "config = {\n",
        "    \"lr\":1e-2,\n",
        "    \"momentum\":0.9,\n",
        "    \"weight_decay\":1e-4,\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = ConvNet(classes_num=100).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYKk56zLCxbk"
      },
      "source": [
        "# Step 4: Train the network and save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAfQYydqC_R7",
        "outputId": "047cbac2-da53-48ac-92e7-8a72a86decfc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "      self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "      self.val   = 0\n",
        "      self.avg   = 0\n",
        "      self.sum   = 0\n",
        "      self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "      self.val   = val\n",
        "      self.sum   += val * n\n",
        "      self.count += n\n",
        "      self.avg   = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,1)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred    = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "      correct_k = correct[:k].view(-1).float().sum(0)\n",
        "      res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res[0]\n",
        "\n",
        "def train(train_loader, net, optimizer, criterion, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time  = AverageMeter()\n",
        "    top1       = AverageMeter()\n",
        "\n",
        "    LOSS = AverageMeter()\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (img, target) in enumerate(train_loader, start=1):\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        img = img.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        out = net(img)\n",
        "\n",
        "        loss = criterion(out, target)\n",
        "\n",
        "        prec1 = accuracy(out, target) # prec1:list\n",
        "        top1.update(prec1.item(), img.size(0))\n",
        "\n",
        "        LOSS.update(loss.item(), img.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 50 == 1:\n",
        "            log_str = ('Epoch[{0}]:[{1:03}/{2:03}] '\n",
        "                       'Time:{batch_time.val:.4f} '\n",
        "                       'Data:{data_time.val:.4f}  '\n",
        "                       'loss:{loss.val:.4f}({loss.avg:.4f})  '\n",
        "                       'prec@1:{top1.val:.2f}({top1.avg:.2f})  '.format(\n",
        "                       epoch, i, len(train_loader), batch_time=batch_time, data_time=data_time,\n",
        "                       loss=LOSS,\n",
        "                       top1=top1))\n",
        "            print(log_str)\n",
        "\n",
        "    return LOSS.avg\n",
        "\n",
        "def save_checkpoint(state, is_best, save_root, epoch):\n",
        "    if not os.path.exists(save_root):\n",
        "        os.makedirs(save_root)\n",
        "    save_path = os.path.join(save_root, 'epoch_{}.pth.tar'.format(str(epoch)))\n",
        "    torch.save(state, save_path)\n",
        "    if is_best:\n",
        "        best_save_path = os.path.join(save_root, 'model_best.pth.tar')\n",
        "        shutil.copyfile(save_path, best_save_path)\n",
        "\n",
        "config = {\n",
        "    \"save_root\":\"./result\",\n",
        "    \"epochs\":3,\n",
        "}\n",
        "\n",
        "best_top1 = 0\n",
        "test_top1 = 0\n",
        "for epoch in range(1, config[\"epochs\"]+1):\n",
        "    # train one epoch\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train(train_loader, net, optimizer, criterion, epoch)\n",
        "\n",
        "    # evaluate on testing set\n",
        "    # test_top1 = test(test_loader, net, criterion)\n",
        "\n",
        "    epoch_duration = time.time() - epoch_start_time\n",
        "    print('Epoch time: {}s'.format(int(epoch_duration)))\n",
        "\n",
        "    # save model\n",
        "    is_best = False\n",
        "    # if test_top1 > best_top1:\n",
        "    #     best_top1 = test_top1\n",
        "    #     is_best = True\n",
        "    print('Saving models......')\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch,\n",
        "        'net': net.state_dict(),\n",
        "        'prec@1': test_top1,\n",
        "    }, is_best, config[\"save_root\"], epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO1MiuPHFpVW"
      },
      "source": [
        "# Step 5: Test on single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFsBN0Z0FxkT",
        "outputId": "c498d1e4-0e97-4e91-8317-a695211475c0"
      },
      "outputs": [],
      "source": [
        "img = Image.open(\"./cifar100/test/apple_9904.jpg\")\n",
        "img = transform_test(img).unsqueeze(0).to(device)\n",
        "out = net(img)\n",
        "predicted_classes = torch.argmax(out, dim=1)\n",
        "tags = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
        "\n",
        "print(tags[predicted_classes[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne7evEhmEI0t"
      },
      "source": [
        "# Step 6: Evaluate model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgH66ll9EV0p",
        "outputId": "d9579d0f-155a-4068-ba05-5c4b0e6e97ec"
      },
      "outputs": [],
      "source": [
        "def test(test_loader, net, criterion):\n",
        "    losses = AverageMeter()\n",
        "    top1   = AverageMeter()\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    for i, (img, target) in enumerate(test_loader, start=1):\n",
        "        img = img.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = net(img)\n",
        "            loss = criterion(out, target)\n",
        "\n",
        "        prec1 = accuracy(out, target) # prec1:list\n",
        "        losses.update(loss.item(), img.size(0))\n",
        "        top1.update(prec1.item(), img.size(0))\n",
        "\n",
        "    f_l = [losses.avg, top1.avg]\n",
        "    print('---------------------------------test classification result---------------------------------')\n",
        "    print('Loss: {:.4f}, Prec@1: {:.2f}%'.format(*f_l))\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "test_top1 = test(test_loader, net, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v4gr3XWJDBQ"
      },
      "source": [
        "# Step 7: T-SNE Visualization\n",
        "\n",
        "##Use hooks in PyTorch to extract feature representations from the intermediate layers of the model for the test set \"testloader\", and visualize them using the T-SNE method. The specific requirements are as follows:\n",
        "####Visualize the features before and after the dual-branch feature fusion. If there are multiple fusions, you may choose specific layers for visualization.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ms-swift-space",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
