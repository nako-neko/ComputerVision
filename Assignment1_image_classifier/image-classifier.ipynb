{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2uffHZLCPMU",
        "outputId": "a2bf1a9b-946a-4b8c-f5f1-f068fe45cc1f"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyxmEoX11W5u"
      },
      "source": [
        "# Step 1: Download a dataset and preview images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCZqRJrYBAff",
        "outputId": "631895c6-65c7-4cdf-8970-4e23237aaf8f"
      },
      "outputs": [],
      "source": [
        "# !tar -xvf './cifar100.tar'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woI6j0f5BTGl"
      },
      "source": [
        "# Step 2: Custom Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnU8jRXoBaX_",
        "outputId": "506e2783-df01-4f8e-d6ec-f3e4af0faf1e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "import torch\n",
        "import shutil\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "config = {\n",
        "    \"data_path\":\"./cifar100\",\n",
        "    \"batch_size\": 128,\n",
        "}\n",
        "\n",
        "class mydataset(Dataset):\n",
        "    def __init__(self, data_dir, flag, transform):\n",
        "        super(mydataset,self).__init__()\n",
        "        self.root       = data_dir\n",
        "        self.label      = flag\n",
        "        self.transform  = transform\n",
        "\n",
        "        self.img_dir = os.path.join(self.root, self.label)\n",
        "        self.img_names  = glob.glob(os.path.join(self.img_dir, '*.jpg'))\n",
        "\n",
        "        self.tags = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
        "\n",
        "    def RGB2Gradient(self, img:torch.tensor):\n",
        "        \"\"\"\n",
        "        Converts an RGB image tensor to its gradient magnitude using Sobel operator.\n",
        "        The output is replicated to 3 channels to match the input dimensions of the other branch.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Define Sobel kernels\n",
        "        sobel_kernel_x = torch.tensor([[-1., 0., 1.], \n",
        "                                       [-2., 0., 2.], \n",
        "                                       [-1., 0., 1.]], dtype=torch.float32).reshape((1, 1, 3, 3))\n",
        "        sobel_kernel_y = torch.tensor([[-1., -2., -1.], \n",
        "                                       [ 0.,  0.,  0.], \n",
        "                                       [ 1.,  2.,  1.]], dtype=torch.float32).reshape((1, 1, 3, 3))\n",
        "\n",
        "        sobel_kernel_x = sobel_kernel_x.to(img.device)\n",
        "        sobel_kernel_y = sobel_kernel_y.to(img.device)\n",
        "\n",
        "        # Convert to grayscale: [3, H, W] -> Output [1, H, W]\n",
        "        # gray_img = img[0, :, :] * 0.2989 + img[1, :, :] * 0.5870 + img[2, :, :] * 0.1140\n",
        "        # gray_img = gray_img.unsqueeze(0)\n",
        "        gray_img = transforms.Grayscale(num_output_channels=1)(img)\n",
        "\n",
        "        # Add batch dimension [1, H, W] -> [1, 1, H, W]\n",
        "        gray_img_batch = gray_img.unsqueeze(0) \n",
        "\n",
        "        # [YOU NEED TO FILL] Apply Sobel filters\n",
        "        # Use F.conv2d, gray_img_batch, and the Sobel kernels (sobel_kernel_x, sobel_kernel_y) \n",
        "        # to calculate the gradients in the x and y directions.\n",
        "        grad_x = F.conv2d(gray_img_batch, sobel_kernel_x, padding=1)\n",
        "        grad_y = F.conv2d(gray_img_batch, sobel_kernel_y, padding=1)\n",
        "        \n",
        "        # [YOU NEED TO FILL] Calculate gradient magnitude ---\n",
        "        # Calculate the magnitude (G = sqrt(Gx^2 + Gy^2)) from grad_x and grad_y.\n",
        "        # The result should be stored in a variable named 'magnitude'.\n",
        "        magnitude = torch.sqrt(grad_x ** 2 + grad_y ** 2)\n",
        "\n",
        "        # Normalize magnitude\n",
        "        mag_min = magnitude.min()\n",
        "        mag_max = magnitude.max()\n",
        "        epsilon = 1e-6 # Avoid division by zero\n",
        "        normalized_magnitude = (magnitude - mag_min) / (mag_max - mag_min + epsilon)\n",
        "        \n",
        "        # Replicate to 3 channels [1, 1, H, W] -> [1, 3, H, W]\n",
        "        normalized_magnitude_3channel = normalized_magnitude.repeat(1, 3, 1, 1)\n",
        "\n",
        "        # Remove batch dimension [1, 3, H, W] -> [3, H, W]\n",
        "        return normalized_magnitude_3channel.squeeze(0)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        img_name = self.img_names[idx]\n",
        "        img = Image.open(os.path.join(img_name)).convert('RGB')\n",
        "        \n",
        "        # original image\n",
        "        img = self.transform(img)\n",
        "        \n",
        "        # gradient image\n",
        "        grad_img = self.RGB2Gradient(img)\n",
        "\n",
        "        for i in range(len(self.tags)):\n",
        "            if self.tags[i] in img_name:\n",
        "                tag = i\n",
        "                break\n",
        "\n",
        "        return img, grad_img, tag\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "\n",
        "cifar100_mean = [0.5071, 0.4865, 0.4409]\n",
        "cifar100_std = [0.2673, 0.2564, 0.2762]\n",
        "transform_train = transforms.Compose(\n",
        "        [transforms.Resize([64, 64]),\n",
        "         transforms.RandomHorizontalFlip(),    # 50% 概率随机水平翻转\n",
        "         transforms.RandomCrop(64, padding=4), # 在图像周围填充4个像素，然后随机裁剪回 64x64\n",
        "         transforms.ToTensor(),\n",
        "         transforms.Normalize(mean=cifar100_mean, std=cifar100_std)])\n",
        "transform_test = transforms.Compose(\n",
        "    [transforms.Resize([64, 64]),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=cifar100_mean, std=cifar100_std)])\n",
        "\n",
        "train_dataset = mydataset(data_dir=config['data_path'], flag= \"train\", transform=transform_train)\n",
        "test_dataset  = mydataset(data_dir=config['data_path'], flag= \"test\", transform=transform_test)\n",
        "\n",
        "# define data loader\n",
        "train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=config['batch_size'], shuffle=True, num_workers=0, pin_memory=True, drop_last=False)\n",
        "\n",
        "test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=config['batch_size'], shuffle=True, num_workers=0, pin_memory=True, drop_last=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0io-L6VCDoB"
      },
      "source": [
        "# Step 3: Configure the Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jvia9QHCHtC"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn import Sequential as Seq\n",
        "\n",
        "class CommonBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel, stride):        # 普通Block简单完成两次卷积操作\n",
        "        super(CommonBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x                                            # 普通Block的shortcut为直连，不需要升维下采样\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)       # 完成一次卷积\n",
        "        x = self.bn2(self.conv2(x))                             # 第二次卷积不加relu激活函数\n",
        "\n",
        "        x += identity                                           # 两路相加\n",
        "        return F.relu(x, inplace=True)                          # 添加激活函数输出\n",
        "\n",
        "class SpecialBlock(nn.Module):                                  # 特殊Block完成两次卷积操作，以及一次升维下采样\n",
        "    def __init__(self, in_channel, out_channel, stride):        # 注意这里的stride传入一个数组，shortcut和残差部分stride不同\n",
        "        super(SpecialBlock, self).__init__()\n",
        "        self.change_channel = nn.Sequential(                    # 负责升维下采样的卷积网络change_channel\n",
        "            nn.Conv2d(in_channel, out_channel, kernel_size=1, stride=stride[0], padding=0, bias=False),\n",
        "            nn.BatchNorm2d(out_channel)\n",
        "        )\n",
        "        self.conv1 = nn.Conv2d(in_channel, out_channel, kernel_size=3, stride=stride[0], padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channel)\n",
        "        self.conv2 = nn.Conv2d(out_channel, out_channel, kernel_size=3, stride=stride[1], padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.change_channel(x)                       # 调用change_channel对输入修改，为后面相加做变换准备\n",
        "\n",
        "        x = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
        "        x = self.bn2(self.conv2(x))                             # 完成残差部分的卷积\n",
        "\n",
        "        x += identity\n",
        "        return F.relu(x, inplace=True)                          # 输出卷积单元\n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    def __init__(self, in_channels, reduction_ratio=16):\n",
        "        super(ChannelAttention, self).__init__()\n",
        "        # 'reduction_ratio' 是为了减少参数量\n",
        "        # 我们首先将通道数压缩，然后再恢复\n",
        "        hidden_dim = max(16, in_channels // reduction_ratio) # 确保 hidden_dim 至少为 16\n",
        "        \n",
        "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(in_channels, hidden_dim, bias=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(hidden_dim, in_channels, bias=False),\n",
        "            nn.Sigmoid() # 使用 Sigmoid 将权重缩放到 0-1 之间\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x 的原始 shape: [Batch, Channels]\n",
        "        \n",
        "        # 1. Squeeze: [B, C] -> [B, C, 1]\n",
        "        x_unsqueeze = x.unsqueeze(2)\n",
        "        \n",
        "        # 2. Squeeze (Global Avg Pool): [B, C, 1] -> [B, C, 1]\n",
        "        y = self.avg_pool(x_unsqueeze) # (在1D上做 avg pool)\n",
        "        \n",
        "        # [B, C, 1] -> [B, C]\n",
        "        y = y.squeeze(2) \n",
        "        \n",
        "        # 3. Excitation (FC layers): [B, C] -> [B, C] (得到权重)\n",
        "        weights = self.fc(y)\n",
        "        \n",
        "        # 4. Rescale: [B, C] * [B, C] -> [B, C]\n",
        "        # 将原始特征 x 与学到的权重 weights 逐元素相乘\n",
        "        return x * weights\n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, classes_num):\n",
        "        super(ConvNet, self).__init__()\n",
        "\n",
        "        # --- RGB 分支 ---\n",
        "        self.prepare_rgb = nn.Sequential(           # 预处理==》[batch, 64, 56, 56]\n",
        "            nn.Conv2d(3, 64, 7, 2, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, 2, 1)\n",
        "        )\n",
        "        self.layer1_rgb = nn.Sequential(            # layer1有点特别，由于输入输出的channel均是64，故两个CommonBlock\n",
        "            CommonBlock(64, 64, 1),\n",
        "            CommonBlock(64, 64, 1)\n",
        "        )\n",
        "        self.layer2_rgb = nn.Sequential(            # layer234类似，由于输入输出的channel不同，故一个SpecialBlock，一个CommonBlock\n",
        "            SpecialBlock(64, 128, [2, 1]),\n",
        "            CommonBlock(128, 128, 1)\n",
        "        )\n",
        "        self.layer3_rgb = nn.Sequential(\n",
        "            SpecialBlock(128, 256, [2, 1]),\n",
        "            CommonBlock(256, 256, 1)\n",
        "        )\n",
        "        self.layer4_rgb = nn.Sequential(\n",
        "            SpecialBlock(256, 512, [2, 1]),\n",
        "            CommonBlock(512, 512, 1)\n",
        "        )\n",
        "        \n",
        "        # --- 梯度分支 ---\n",
        "        self.prepare_grad = nn.Sequential(           # 预处理==》[batch, 64, 56, 56]\n",
        "            nn.Conv2d(3, 64, 7, 2, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, 2, 1)\n",
        "        )\n",
        "        self.layer1_grad = nn.Sequential(            # layer1有点特别，由于输入输出的channel均是64，故两个CommonBlock\n",
        "            CommonBlock(64, 64, 1),\n",
        "            CommonBlock(64, 64, 1)\n",
        "        )\n",
        "        self.layer2_grad = nn.Sequential(            # layer234类似，由于输入输出的channel不同，故一个SpecialBlock，一个CommonBlock\n",
        "            SpecialBlock(64, 128, [2, 1]),\n",
        "            CommonBlock(128, 128, 1)\n",
        "        )\n",
        "        self.layer3_grad = nn.Sequential(\n",
        "            SpecialBlock(128, 256, [2, 1]),\n",
        "            CommonBlock(256, 256, 1)\n",
        "        )\n",
        "        self.layer4_grad = nn.Sequential(\n",
        "            SpecialBlock(256, 512, [2, 1]),\n",
        "            CommonBlock(512, 512, 1)\n",
        "        )\n",
        "\n",
        "        # --- 融合和分类头 ---\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.flatten = nn.Flatten(start_dim=1)\n",
        "        \n",
        "        # 注意力层\n",
        "        self.attention = ChannelAttention(in_channels=1024)\n",
        "        \n",
        "        # 融合层\n",
        "        self.fc_fused = nn.Linear(512 + 512, 1024)\n",
        "        self.dropout = nn.Dropout(p=0.3) # Dropout 层\n",
        "        self.relu = nn.ReLU()\n",
        "        \n",
        "        # 分类器\n",
        "        self.classifier = nn.Linear(1024, classes_num)\n",
        "        \n",
        "        # self.head = Seq(nn.AdaptiveAvgPool2d(1),\n",
        "        #           nn.Flatten(start_dim=1),\n",
        "        #           nn.Linear(512, classes_num))\n",
        "\n",
        "    def forward(self, x_rgb, x_grad):\n",
        "        # x = self.prepare(x)         # 预处理\n",
        "\n",
        "        # x = self.layer1(x)          # 四个卷积单元\n",
        "        # x = self.layer2(x)\n",
        "        # x = self.layer3(x)\n",
        "        # x = self.layer4(x)\n",
        "\n",
        "        # x = self.head(x)\n",
        "\n",
        "        # return x\n",
        "        \n",
        "        # RGB 分支\n",
        "        x_rgb = self.prepare_rgb(x_rgb)           # 预处理\n",
        "        x_rgb = self.layer1_rgb(x_rgb)            # 四个卷积单元\n",
        "        x_rgb = self.layer2_rgb(x_rgb)\n",
        "        x_rgb = self.layer3_rgb(x_rgb)\n",
        "        x_rgb = self.layer4_rgb(x_rgb)\n",
        "        x_rgb = self.flatten(self.pool(x_rgb))    # [Batch, 512]\n",
        "        \n",
        "        # 梯度分支\n",
        "        x_grad = self.prepare_grad(x_grad)        # 预处理\n",
        "        x_grad = self.layer1_grad(x_grad)         # 四个卷积单元\n",
        "        x_grad = self.layer2_grad(x_grad)\n",
        "        x_grad = self.layer3_grad(x_grad)\n",
        "        x_grad = self.layer4_grad(x_grad)\n",
        "        x_grad = self.flatten(self.pool(x_grad))  # [Batch, 512]\n",
        "\n",
        "        # 特征融合\n",
        "        x_fused = torch.cat((x_rgb, x_grad), dim=1)      # 拼接 [Batch, 1024]\n",
        "        \n",
        "        x_fused = self.attention(x_fused)                # 注意力机制增强特征\n",
        "        \n",
        "        # 融合后处理\n",
        "        x_processed = self.relu(self.fc_fused(x_fused))  # [Batch, 1024]\n",
        "        x_processed = self.dropout(x_processed)\n",
        "        \n",
        "        # 最终分类\n",
        "        x_out = self.classifier(x_processed)             # [Batch, classes_num]\n",
        "\n",
        "        return x_out\n",
        "\n",
        "config = {\n",
        "    \"lr\": 1e-3,\n",
        "    \"momentum\": 0.9,\n",
        "    \"weight_decay\": 1e-4,\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "net = ConvNet(classes_num=100).to(device)\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=config[\"lr\"], momentum=config[\"momentum\"], weight_decay=config[\"weight_decay\"])\n",
        "# AdamW 优化器\n",
        "optimizer = torch.optim.AdamW(net.parameters(), lr=config[\"lr\"], weight_decay=config[\"weight_decay\"])\n",
        "# 学习率调度器\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10) # T_max = num_epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYKk56zLCxbk"
      },
      "source": [
        "# Step 4: Train the network and save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OAfQYydqC_R7",
        "outputId": "047cbac2-da53-48ac-92e7-8a72a86decfc"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "      self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "      self.val   = 0\n",
        "      self.avg   = 0\n",
        "      self.sum   = 0\n",
        "      self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "      self.val   = val\n",
        "      self.sum   += val * n\n",
        "      self.count += n\n",
        "      self.avg   = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,1)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred    = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "      correct_k = correct[:k].view(-1).float().sum(0)\n",
        "      res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res[0]\n",
        "\n",
        "def train(train_loader, net, optimizer, criterion, epoch):\n",
        "    batch_time = AverageMeter()\n",
        "    data_time  = AverageMeter()\n",
        "    top1       = AverageMeter()\n",
        "\n",
        "    LOSS = AverageMeter()\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (img_rgb, img_grad, target) in enumerate(train_loader, start=1):\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        img_rgb = img_rgb.to(device)\n",
        "        img_grad = img_grad.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        out = net(img_rgb, img_grad)\n",
        "\n",
        "        loss = criterion(out, target)\n",
        "\n",
        "        prec1 = accuracy(out, target) # prec1:list\n",
        "        top1.update(prec1.item(), img_rgb.size(0))\n",
        "\n",
        "        LOSS.update(loss.item(), img_rgb.size(0))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % 50 == 1:\n",
        "            log_str = ('Epoch[{0}]:[{1:03}/{2:03}] '\n",
        "                       'Time:{batch_time.val:.4f} '\n",
        "                       'Data:{data_time.val:.4f}  '\n",
        "                       'loss:{loss.val:.4f}({loss.avg:.4f})  '\n",
        "                       'prec@1:{top1.val:.2f}({top1.avg:.2f})  '.format(\n",
        "                       epoch, i, len(train_loader), batch_time=batch_time, data_time=data_time,\n",
        "                       loss=LOSS,\n",
        "                       top1=top1))\n",
        "            print(log_str)\n",
        "\n",
        "    return LOSS.avg\n",
        "\n",
        "def save_checkpoint(state, is_best, save_root, epoch):\n",
        "    if not os.path.exists(save_root):\n",
        "        os.makedirs(save_root)\n",
        "    save_path = os.path.join(save_root, 'epoch_{}.pth.tar'.format(str(epoch)))\n",
        "    torch.save(state, save_path)\n",
        "    if is_best:\n",
        "        best_save_path = os.path.join(save_root, 'model_best.pth.tar')\n",
        "        shutil.copyfile(save_path, best_save_path)\n",
        "\n",
        "config = {\n",
        "    \"save_root\": \"./result\",\n",
        "    \"epochs\": 10,\n",
        "}\n",
        "\n",
        "best_top1 = 0\n",
        "test_top1 = 0\n",
        "for epoch in range(1, config[\"epochs\"]+1):\n",
        "    # train one epoch\n",
        "    epoch_start_time = time.time()\n",
        "    train_loss = train(train_loader, net, optimizer, criterion, epoch)\n",
        "\n",
        "    if 'scheduler' in locals(): # 检查 scheduler 是否已定义\n",
        "        scheduler.step()\n",
        "\n",
        "    # evaluate on testing set\n",
        "    # test_top1 = test(test_loader, net, criterion)\n",
        "\n",
        "    epoch_duration = time.time() - epoch_start_time\n",
        "    print('Epoch time: {}s'.format(int(epoch_duration)))\n",
        "\n",
        "    # save model\n",
        "    is_best = False\n",
        "    # if test_top1 > best_top1:\n",
        "    #     best_top1 = test_top1\n",
        "    #     is_best = True\n",
        "    print('Saving models......')\n",
        "    save_checkpoint({\n",
        "        'epoch': epoch,\n",
        "        'net': net.state_dict(),\n",
        "        'prec@1': test_top1,\n",
        "    }, is_best, config[\"save_root\"], epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO1MiuPHFpVW"
      },
      "source": [
        "# Step 5: Test on single image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFsBN0Z0FxkT",
        "outputId": "c498d1e4-0e97-4e91-8317-a695211475c0"
      },
      "outputs": [],
      "source": [
        "img = Image.open(\"./cifar100/test/apple_9904.jpg\")\n",
        "# img = transform_test(img).unsqueeze(0).to(device)\n",
        "img_rgb = transform_test(img)\n",
        "img_grad = test_dataset.RGB2Gradient(img_rgb)\n",
        "\n",
        "img_rgb = img_rgb.unsqueeze(0).to(device)\n",
        "img_grad = img_grad.unsqueeze(0).to(device)\n",
        "\n",
        "out = net(img_rgb, img_grad)\n",
        "predicted_classes = torch.argmax(out, dim=1)\n",
        "tags = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']\n",
        "\n",
        "print(tags[predicted_classes[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ne7evEhmEI0t"
      },
      "source": [
        "# Step 6: Evaluate model accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgH66ll9EV0p",
        "outputId": "d9579d0f-155a-4068-ba05-5c4b0e6e97ec"
      },
      "outputs": [],
      "source": [
        "def test(test_loader, net, criterion):\n",
        "    losses = AverageMeter()\n",
        "    top1   = AverageMeter()\n",
        "\n",
        "    net.eval()\n",
        "\n",
        "    for i, (img_rgb, img_grad, target) in enumerate(test_loader, start=1):\n",
        "        img_rgb = img_rgb.to(device)\n",
        "        img_grad = img_grad.to(device)\n",
        "        target = target.to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = net(img_rgb, img_grad)\n",
        "            loss = criterion(out, target)\n",
        "\n",
        "        prec1 = accuracy(out, target) # prec1:list\n",
        "        losses.update(loss.item(), img_rgb.size(0))\n",
        "        top1.update(prec1.item(), img_rgb.size(0))\n",
        "\n",
        "    f_l = [losses.avg, top1.avg]\n",
        "    print('---------------------------------test classification result---------------------------------')\n",
        "    print('Loss: {:.4f}, Prec@1: {:.2f}%'.format(*f_l))\n",
        "\n",
        "    return top1.avg\n",
        "\n",
        "test_top1 = test(test_loader, net, criterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0v4gr3XWJDBQ"
      },
      "source": [
        "# Step 7: T-SNE Visualization\n",
        "\n",
        "## Use hooks in PyTorch to extract feature representations from the intermediate layers of the model for the test set \"testloader\", and visualize them using the T-SNE method. The specific requirements are as follows:\n",
        "#### Visualize the features before and after the dual-branch feature fusion. If there are multiple fusions, you may choose specific layers for visualization.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
